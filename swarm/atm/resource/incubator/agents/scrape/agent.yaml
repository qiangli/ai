###
pack: "scrape"

model: "llm/fast"
log_level: "info"
agents:
  # - name: "save_result"
  #   display: Save response as result in the environment
  #   description: |
  #     Use the `sh:set_envs` tool to store the response with the key `result`.
  #   model: "llm/smart"
  #   arguments:
  #     result_key: "result"
  #   instruction: |
  #     *** Important ***
  #     You must save the response using the `ai:set_envs` tool with `{{.result_key}}` as the key.
  #     Ensure the values are correctly stored by using the `ai:get_envs` tool to verify.
  #     ###
  #   functions:
  #     - "sh:set_envs"
  #     - "sh:get_envs"

  - name: "search"
    display: "üîç Web Search"
    description: "Get web search results for a given query."
    model: "llm/fast"
    # arguments:
    #   original_query: "{{.message}}"
    # embed:
    #   - "agent:gptr/save_result"
    # message: |
    #   #! --mime-type=text/x-go-template
    #   search the web for the following content:
    #   {{.original_query}}
    instruction: |
      As a web search assistant, you are responsible for processing user queries and providing accurate
      search results from the web. When a user submits a query, analyze the main components of the query,
      perform a web search, and return the most relevant results.
    functions:
      - "web:*"

  - name: "research_queries"
    display: "ü§î Planning the research strategy and subtasks"
    description: "Generate sub_queries using the specified LLM model."
    model: "llm/strategic"
    # embed:
    #   - "agent:gptr/save_result"
    arguments:
      # max_completion_tokens: 8000
      reasoning_effort: medium
      #
      max_iterations: 3
    instruction: |
      #! --mime-type=x-go-template
      You are a seasoned research assistant tasked with generating search queries to find relevant information.

      Use this context to inform and refine your search queries. The context provides real-time web information
      that can help you generate more specific and relevant queries. Consider any current events, recent developments,
      or specific details mentioned in the context that could enhance the search queries.

      Write {{.max_iterations}} search queries to search online that form an objective opinion from the following task:
      "{{.original_query}}"

      Assume the current date is {{.now}} if required.

      You must respond with a list of strings in the following JSON array object format:
        [
          "query 1",
          "query 2",
          ...
        ]
      The response should contain ONLY the list.

  - name: "scrape"
    display: "üåê Scraper"
    description: |
      Executes a query across multiple retrievers to scrape content from specified URLs.
    message: |
      #! --mime-type=x-go-template
      Run the `agent:gptr/crawl` for the following:
      {{.result}}
    embed:
      - "agent:gptr/save_result"
    instruction: |
      Verify if the input query is a list of strings in JSON format. If it is, proceed with it; otherwise, convert the input to a JSON list of strings.

      Ensure the query contains only the JSON list as the next tool will parse it strictly as such.

      Execute the `agent:gptr/crawl` to gather the contents.
    functions:
      - "agent:gptr/crawl"

  - name: "crawl"
    display: "üåê Web Crawler"
    description: "Runs a query across multiple retrievers and scrapes the resulting URLs."
    arguments:
      maximum_attempts: 5
    instruction: |
      #! --mime-type=text/x-go-template
      You are a specialized web crawler. The maximum attempts allowed are {{.maximum_attempts}}.
      For each query, execute a search and follow only the immediate links one level deep.
      If the fetch returns empty results or errors, continue with more search and fetch tool calls.
      Collect and merge the content from these pages to provide comprehensive information 
      relevant to the user query.
    functions:
      - "web:*"

  
## tool kit
kit: "gptr"
tools:
  - name: "research"
    display: "Research Tool"
    description: |
      This tool produces detailed, factual, and unbiased research reports with citations.
      ‚Ä¢ Create a task-specific agent based on a research query.                                       
      ‚Ä¢ Generate questions that collectively form an objective opinion on the task.                   
      ‚Ä¢ Use a crawler agent to gather information for each question.                                  
      ‚Ä¢ Summarize and source-track each resource.                                                     
      ‚Ä¢ Filter and aggregate the summaries into a final research report.
    parameters:
      type: "object"
      properties:
        original_query:
          type: "string"
          description: "The original query from user"
    type: "func"
    body:
      mime_type: "application/x-sh"
      script: |
        #!/bin/bash
        echo "Creating task specific agent and setting up default values..."
        /flow:parallel --option actions="[agent:gptr/user_input,agent:gptr/choose_agent]"

        printenv

        echo "Researching..."
        # /flow:sequence --option actions="[agent:gptr/web_search,agent:gptr/research_queries,agent:gptr/scrape]"

        echo "Publishing..."
        # /flow:sequence --option actions="[agent:gptr/curate,agent:gptr/report]"

## models
set: llm
provider: "openai"
base_url: "https://api.openai.com/v1/"
api_key: "openai"
models:
  fast:
    model: "gpt-4o-mini"
  smart:
    model: "gpt-4.1"
  strategic:
    model: "o4-mini"
###
