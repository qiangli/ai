###
pack: "gptr"
#
# adapted from https://github.com/assafelovic/gpt-researcher
#
model: "llm/fast"
log_level: "info"
agents:
  - name: "gptr"
    display: "üöÄ GPT Researcher"
    description: |
      GPT Researcher is an agent designed for research on any given task.
      The agent produces detailed, factual, and unbiased research reports with citations.
      ‚Ä¢ Create a task-specific agent based on a research query.
      ‚Ä¢ Generate questions that collectively form an objective opinion on the task.
      ‚Ä¢ Use a crawler agent to gather information for each question.
      ‚Ä¢ Summarize and source-track each resource.
      ‚Ä¢ Filter and aggregate the summaries into a final research report.
    embed:
      - "agent:kbase"
      - "agent:memory"
    instruction: |
      You are a researcher agent designed for research on any given task.
      Please execute the tool `gptr:research` to perform research.

      Once completed successfully. You should save the final report in the workspace with an fitting name based on user query.
    functions:
      - "gptr:research"
      - "fs:*"

  - name: "user_input"
    new: true
    display: "üñ•Ô∏è  User Input"
    description: "Detect user preferences for the GPT Researcher tool."
    arguments:
      query: "{{.message}}"
    instruction: |
      You are an agent designed to analyze user input to identify preferences for generating research reports. Your role is not to gather or retrieve real-time information, but to extract the specified parameters from the user's query.

      Your objective is to identify the following elements from the user's input:

      + Tone of the report:
        Example values:
          "objective", "formal", "analytical", "persuasive", "informative", "explanatory", "descriptive", "critical", "comparative", "speculative",
          "reflective", "narrative", "humorous", "optimistic", "pessimistic"
        Multiple values are allowed, e.g., "formal, analytical, and objective". If a tone not listed above is detected in the user's input, it should also be considered valid.

      + Total word count limit for document generation. The default is `500`.
        Guidelines:
          - Use 500 words for a short summary.
          - Use 1000 words for a detailed and in-depth report.
          - Do not exceed 2000 words for an extensive research report unless explicitly requested by the user for more.

      + Report format: The preferred format for report generation. The default is `markdown`.
        Formats such as `MLA`, `CMS`, `Harvard style`, `IEEE`, etc., should be used if specified by the user.

      + Language: The language to be used for the final research report. The default is `English`.

      The final response as well as the user's original query must be saved using the `ai:set_envs` tool.
      {
        "tone": "detected tone from user input",
        "total_words": "derived total words from user input",
        "report_format": "desired report format from user",
        "language": "preferred language by user",
        "original_query": "users original query"
      }
      You must verify that the values are saved correctly using the "ai:get_envs" tool call.
    environment:
      tone: "objective"
      total_words: 500
      report_format: "markdown"
      language: "english"
    functions:
      - "sh:set_envs"
      - "sh:get_envs"

  - name: "choose_agent"
    display: "ü§ñ Choose Agent"
    description: "Chooses the agent automatically"
    model: "llm/smart"
    arguments:
      # temperature: 0.15
      query: "{{.message}}"
    instruction: |
      This task involves researching a given topic, regardless of its complexity or the availability of a definitive answer.
      The research is conducted by a specific server, defined by its type and role, with each server requiring distinct instructions.

      The server is determined by the field of the topic and the specific name of the server that could be utilized to research the topic provided.
      Agents are categorized by their area of expertise, and each server type is associated with a corresponding emoji.

      Examples:

      task: "should I invest in apple stocks?"
      response:
      {
          "server": "üí∞ Finance Agent",
          "agent_role_prompt: "You are a seasoned finance analyst AI assistant. Your primary goal is to compose comprehensive, astute, impartial, and methodically arranged financial reports based on provided data and trends."
      }
      task: "could reselling sneakers become profitable?"
      response:
      {
          "server":  "üìà Business Analyst Agent",
          "agent_role_prompt": "You are an experienced AI business analyst assistant. Your main objective is to produce comprehensive, insightful, impartial, and systematically structured business reports based on provided business data, market trends, and strategic analysis."
      }
      task: "what are the most interesting sites in Tel Aviv?"
      response:
      {
          "server":  "üåç Travel Agent",
          "agent_role_prompt": "You are a world-travelled AI tour guide assistant. Your main purpose is to draft engaging, insightful, unbiased, and well-structured travel reports on given locations, including history, attractions, and cultural insights."
      }

      *** Important ***
      You response must also be saved using the `ai:set_envs` tool using `server` and `agent_role_prompt` as the names.
      and You must verify that the values are saved correctly using the "ai:get_envs" tool call.
    functions:
      - "sh:set_envs"
      - "sh:get_envs"

  - name: "save_response"
    display: Save response as result in the environment
    description: |
      Use the `sh:set_envs` tool to store the response with the key `result`.
    model: "llm/smart"
    instruction: |
      *** Important ***
      You must save the response using the `ai:set_envs` tool with `resp_result` as the key.
      Ensure the values are correctly stored by using the `ai:get_envs` tool to verify.
    functions:
      - "sh:set_envs"
      - "sh:get_envs"

  - name: "web_search"
    display: "üîç Web Search"
    description: "Get web search results for a given query."
    model: "llm/fast"
    embed:
      - "agent:gptr/save_response"
    message: |
      #! --mime-type=text/x-go-template
      search the web for the following content:
      {{.original_query}}
    instruction: |
      As a web search assistant, you are responsible for processing user queries and providing accurate
      search results from the web. When a user submits a query, analyze the main components of the query,
      perform a web search, and return the most relevant results.
    functions:
      - "web:*"

  - name: "research_queries"
    display: "ü§î Planning the research strategy and subtasks"
    description: "Generate sub_queries using the specified LLM model."
    model: "llm/strategic"
    embed:
      - "agent:gptr/save_response"
    arguments:
      # max_completion_tokens: 8000
      reasoning_effort: medium
      #
      max_iterations: 3
    instruction: |
      #! --mime-type=x-go-template
      You are a seasoned research assistant tasked with generating search queries to find relevant information for the following task:
      "{{.original_query}}".
    message: |
      #! --mime-type=x-go-template
      Context: {{.resp_result}}

      Use this context to inform and refine your search queries. The context provides real-time web information
      that can help you generate more specific and relevant queries. Consider any current events, recent developments,
      or specific details mentioned in the context that could enhance the search queries.

      Write {{.max_iterations}} search queries to search online that form an objective opinion from the following task:
      "{{.original_query}}"

      Assume the current date is {{.now}} if required.

      You must respond with a list of strings in the following JSON array object format:
        [
          "query 1",
          "query 2",
          ...
        ]
      The response should contain ONLY the list.

  - name: "scrape"
    display: "üåê Scraper"
    description: |
      Executes a query across multiple retrievers to scrape content from specified URLs.
    message: |
      #! --mime-type=x-go-template
      Run the `agent:gptr/crawl` for the following:
      {{.resp_result}}
    embed:
      - "agent:gptr/save_response"
    instruction: |
      Verify if the input query is a list of strings in JSON format. If it is, proceed with it; otherwise, convert the input to a JSON list of strings.

      Ensure the query contains only the JSON list as the next tool will parse it strictly as such.

      Execute the `agent:gptr/crawl` to gather the contents.
    functions:
      - "agent:gptr/crawl"

  - name: "crawl"
    display: "üåê Web Crawler"
    description: "Runs a query across multiple retrievers and scrapes the resulting URLs."
    arguments:
      maximum_attempts: 5
    instruction: |
      #! --mime-type=text/x-go-template
      You are a specialized web crawler. The maximum attempts allowed are {{.maximum_attempts}}.
      For each query, execute a search and follow only the immediate links one level deep.
      If the fetch returns empty results or errors, continue with more search and fetch tool calls.
      Collect and merge the content from these pages to provide comprehensive information 
      relevant to the user query.
    functions:
      - "web:*"

  - name: "curate"
    display: "‚öñÔ∏è Evaluating and curating sources"
    description: "Ranks sources and curates data based on their relevance, credibility and reliability."
    model: "llm/smart"
    embed:
      - "agent:gptr/save_response"
    arguments:
      # temperature: 0.2
      # max_completion_tokens: 10000
      #
      max_results: 5
    instruction: |
      #! --mimte-type=text/x-go-template
      {{.agent_role_prompt}}
    message: |
      #! --mime-type=text/x-go-template
      Your goal is to evaluate and curate the provided scraped content for the research task: "{{.original_query}}"
        while prioritizing the inclusion of relevant and high-quality information, especially sources containing statistics, numbers, or concrete data.

      The final curated list will be used as context for creating a research report, so prioritize:
      - Retaining as much original information as possible, with extra emphasis on sources featuring quantitative data or unique insights
      - Including a wide range of perspectives and insights
      - Filtering out only clearly irrelevant or unusable content

      EVALUATION GUIDELINES:
      1. Assess each source based on:
        - Relevance: Include sources directly or partially connected to the research query. Err on the side of inclusion.
        - Credibility: Favor authoritative sources but retain others unless clearly untrustworthy.
        - Currency: Prefer recent information unless older data is essential or valuable.
        - Objectivity: Retain sources with bias if they provide a unique or complementary perspective.
        - Quantitative Value: Give higher priority to sources with statistics, numbers, or other concrete data.
      2. Source Selection:
        - Include as many relevant sources as possible, up to {{.max_results}}, focusing on broad coverage and diversity.
        - Prioritize sources with statistics, numerical data, or verifiable facts.
        - Overlapping content is acceptable if it adds depth, especially when data is involved.
        - Exclude sources only if they are entirely irrelevant, severely outdated, or unusable due to poor content quality.
      3. Content Retention:
        - DO NOT rewrite, summarize, or condense any source content.
        - Retain all usable information, cleaning up only clear garbage or formatting issues.
        - Keep marginally relevant or incomplete sources if they contain valuable data or insights.

      SOURCES LIST TO EVALUATE:
      {{toPrettyJson .resp_result}}

      You MUST return your response in the EXACT sources JSON list format as the original sources.
      The response MUST not contain any markdown format or additional text (like ```json), just the JSON list!

  - name: "report"
    display: "üìù Report"
    description: "Generates the final report"
    model: "llm/smart"
    embed:
      - "agent:gptr/save_response"
    arguments:
      # temperature: 0.35
      # max_completion_tokens: 10000
      #
      # tone: "objective"
      # language: "english"
      # report_format: "markdown"
      # total_words: 1200
      date: "{{now}}"
    instruction: |
      #! --mime-type=text/x-go-template
      {{.agent_role_prompt}}
    message: |
      #! --mime-type=text/x-go-template
      {{if not .resp_result}}
        Result is missing. Report error to user and exit!
      {{else}}
      Information:
        "{{toPrettyJson .resp_result}}"
      {{end}}
      ---
      Using the above information, answer the following query or task: "{{.original_query}}" in a detailed report --
      The report should focus on the answer to the query, should be well structured, informative,
      in-depth, and comprehensive, with facts and numbers if available and at least {{.total_words}} words.
      You should strive to write the report as long as you can using all relevant and necessary information provided.

      Please follow all of the following guidelines in your report:
      - You MUST determine your own concrete and valid opinion based on the given information. Do NOT defer to general and meaningless conclusions.
      - You MUST write the report with markdown syntax and {{.report_format}} format.
      - Structure your report with clear markdown headers: use # for the main title, ## for major sections, and ### for subsections.
      - Use markdown tables when presenting structured data or comparisons to enhance readability.
      - You MUST prioritize the relevance, reliability, and significance of the sources you use. Choose trusted sources over less reliable ones.
      - You must also prioritize new articles over older articles if the source can be trusted.
      - You MUST NOT include a table of contents, but DO include proper markdown headers (# ## ###) to structure your report clearly.
      - Use in-text citation references in {{.report_format}} format and make it with markdown hyperlink placed at the end of the sentence or paragraph that references them like this: ([in-text citation](url)).
      - Don't forget to add a reference list at the end of the report in {{.report_format}} format and full url links without hyperlinks.
      - You MUST write all used source urls at the end of the report as references, and make sure to not add duplicated sources, but only one reference for each.
          Every url should be hyperlinked: [url website](url)
          Additionally, you MUST include hyperlinks to the relevant URLs wherever they are referenced in the report:

          eg: Author, A. A. (Year, Month Date). Title of web page. Website Name. [url website](url)
      - Write the report in a {{.tone}} tone.

      You MUST write the report in the following language: {{.language}}.
      The report SHOULD be approximately {{.total_words}} words long.
      Assume that the current date is {{.date}}.

## tool kit
kit: "gptr"
tools:
  - name: "research"
    display: "Research Tool"
    description: |
      This tool produces detailed, factual, and unbiased research reports with citations.
      ‚Ä¢ Create a task-specific agent based on a research query.                                       
      ‚Ä¢ Generate questions that collectively form an objective opinion on the task.                   
      ‚Ä¢ Use a crawler agent to gather information for each question.                                  
      ‚Ä¢ Summarize and source-track each resource.                                                     
      ‚Ä¢ Filter and aggregate the summaries into a final research report.
    parameters: {}
    type: "func"
    body:
      mime_type: "application/x-sh"
      script: |
        #!/bin/bash
        echo "Creating task specific agent and setting up default values..."
        /flow:parallel --option actions="[agent:gptr/user_input,agent:gptr/choose_agent]"

        echo "Researching..."
        /flow:sequence --option actions="[agent:gptr/web_search,agent:gptr/research_queries,agent:gptr/scrape]"

        echo "Publishing..."
        /flow:sequence --option actions="[agent:gptr/curate,agent:gptr/report]"

## models
set: llm
provider: "openai"
base_url: "https://api.openai.com/v1/"
api_key: "openai"
models:
  fast:
    model: "gpt-4o-mini"
  smart:
    model: "gpt-4.1"
  strategic:
    model: "o4-mini"
###
