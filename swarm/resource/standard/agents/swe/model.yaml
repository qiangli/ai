###
# Models (local to this pack)
# Keep L1/L2/L3 aligned across providers.
#
# Docs:
# - OpenAI models: https://platform.openai.com/docs/models
# - Anthropic models: https://docs.anthropic.com/en/docs/about-claude/models
# - Google Gemini models: https://ai.google.dev/gemini-api/docs/models
# Pricing:
# - OpenAI: https://openai.com/pricing
# - Anthropic: https://www.anthropic.com/pricing
# - Google: https://ai.google.dev/pricing

set: "swe"
models:
  # L1: low cost, fast routing/triage
  L1:
    model: "gpt-5-nano"  # low cost; fast for routing + small tasks
    provider: "openai"
    base_url: "https://api.openai.com/v1/"
    api_key: "openai"
    description: "low cost; fast routing/triage, short answers"
  # L2: mid cost, general SWE reasoning + coding
  L2:
    model: "gpt-5-mini"  # mid cost; good general coding + reasoning
    provider: "openai"
    base_url: "https://api.openai.com/v1/"
    api_key: "openai"
    description: "mid cost; general software engineering, planning + coding"
  # L3: higher quality for architecture / hard debugging
  L3:
    model: "gpt-5.2"     # high cost; stronger reasoning for architecture
    provider: "openai"
    base_url: "https://api.openai.com/v1/"
    api_key: "openai"
    description: "high cost; architecture, complex debugging, multi-step plans"
