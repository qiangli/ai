#!/usr/bin/env ai /agent:council/council --script

#
# LLM Council (3-stage orchestration) as a self-contained YAML agent pack.
# Source concept: ./llm-council/README.md (top section "LLM Council")
#
# Stages:
# 1) First opinions: council members answer independently
# 2) Review: council members rank anonymized answers
# 3) Chairman: synthesizes final response from stage1 + stage2
#

---
pack: "council"
log_level: "info"

agents:
  # ------------------------------------------------------------
  # Orchestrator
  # ------------------------------------------------------------
  - name: "council"
    display: "üèõÔ∏è LLM Council"
    description: "3-stage multi-model council: parallel answers ‚Üí anonymized peer ranking ‚Üí chairman synthesis (agent-based)."
    model: "default/any"
    embed:
      - "agent:context/lastn"
      - "agent:memory/long_term"
    parameters:
      type: "object"
      properties:
        council_models:
          type: "string"
          description: "JSON array of model aliases"
          default: '["openai/L2","gemini/L2","anthropic/L2","xai/L2"]'
        chairman_model:
          type: "string"
          description: "model alias for synthesis"
          default: "openai/L3"
        title_model:
          type: "string"
          description: "model alias for title generation"
          default: "openai/L1"
        council_size:
          type: integer
          description: ""
          default: 4
    instruction: |
      #! mime-type=text/x-go-template
      You orchestrate an LLM Council process exactly as described below.

      Council definition (from README):
      - Stage 1: multiple models answer independently; show each response.
      - Stage 2: each model reviews and ranks anonymized responses.
      - Stage 3: a Chairman model synthesizes a single final answer.

      Inputs:
      - The user's message is the query.

      Default configuration:
      - council models: {{.council_models}}
      - chairman model: {{.chairman_model}}
      - title model: {{.title_model}}
      - council size: {{.council_size}}

      You MUST follow these stages:

      Stage 1 (First opinions)
      - For each council model, call sub-agent council/member_answer with that model and the user query.
      - Collect successful results into stage1 as: [{model, response}].
      - If all members fail, return JSON with empty stage1/stage2 and stage3.response = error.

      Stage 2 (Review & ranking)
      - Create anonymized labels Response A, Response B, ... for each stage1 response.
      - Build label_to_model mapping: {"Response A": "<model>", ...}.
      - Build a single ranking prompt (verbatim format requirements below) and send it to each council model via council/member_rank.
      - Each stage2 item: {model, ranking, parsed_ranking}.
      - Parse parsed_ranking from ranking text using council/ranking_parser (extract ordered list of "Response X"; prefer FINAL RANKING section).
      - Compute aggregate_rankings as average position per original model using council/aggregate_ranker.

      Stage 3 (Chairman synthesis)
      - Send chairman model a synthesis prompt containing original question, stage1 (with model names), stage2 (with model names).
      - Get stage3 as {model, response}.

      Title
      - Use council/title_generator to create a 3‚Äì5 word title (best effort).

      Output
      - Return a JSON object with keys: stage1, stage2, stage3, metadata.
      - metadata must include: label_to_model, aggregate_rankings, title, council_models, chairman_model, title_model.

      Ranking prompt format requirements (must be enforced in stage2 prompt):
      - The model MUST include a section starting with exactly: "FINAL RANKING:"
      - Then a numbered list where each line is: "1. Response A" etc.
      - No extra text in the ranking section.

      Tool/agent usage rules:
      - Use agent-based orchestration.
      - You may call ai:call_llm directly only inside helper agents (member_answer/member_rank/chairman/title_generator) OR when strictly necessary.
      - Keep the returned JSON strictly machine-readable.
    functions:
      - "agent:council/member_answer"
      - "agent:council/member_rank"
      - "agent:council/chairman"
      - "agent:council/title_generator"
      - "agent:council/ranking_parser"
      - "agent:council/aggregate_ranker"
    entrypoint:
      - "ai:new_agent"
      - "ai:build_query"
      - "ai:build_prompt"
      - "ai:call_llm"

  # ------------------------------------------------------------
  # Stage 1: council member answers
  # ------------------------------------------------------------
  - name: "member_answer"
    display: "Council Member (Answer)"
    description: "Ask a specific model to answer the user query."
    model: "default/any"
    parameters:
      type: "object"
      properties:
        model:
          type: "string"
          description: "Target model alias/ID to use for this member."
        query:
          type: "string"
          description: "User question to answer."
      required:
        - model
        - query
    instruction: |
      #! mime-type=text/x-go-template
      You are a council member answering a user question.

      You MUST call ai:call_llm exactly once with:
      - model: {{ .model }}
      - query: {{ .query }}

      Return ONLY a JSON object: {"model":"...","response":"..."}.
      - model must echo the provided model.
      - response must be the LLM answer text.
      - If the LLM call fails, return {"model":"...","error":"..."}.
    functions:
      - "ai:call_llm"

  # ------------------------------------------------------------
  # Stage 2: council member ranks anonymized responses
  # ------------------------------------------------------------
  - name: "member_rank"
    display: "Council Member (Rank)"
    description: "Ask a specific model to critique and rank anonymized responses."
    model: "default/any"
    parameters:
      type: "object"
      properties:
        model:
          type: "string"
          description: "Target model alias/ID to use for this member."
        query:
          type: "string"
          description: "Original user question."
        responses_text:
          type: "string"
          description: "Anonymized responses block (Response A..., Response B...)."
      required:
        - model
        - query
        - responses_text
    instruction: |
      #! mime-type=text/x-go-template
      You are a council member reviewing anonymized responses.

      You MUST call ai:call_llm exactly once with:
      - model: {{ .model }}
      - query: a ranking prompt that includes:
        Question: {{ .query }}
        Anonymized responses block: {{ .responses_text }}
        And the required ranking format instructions.

      Ranking instructions MUST be included verbatim:
      IMPORTANT: Your final ranking MUST be formatted EXACTLY as follows:
      - Start with the line "FINAL RANKING:" (all caps, with colon)
      - Then list the responses from best to worst as a numbered list
      - Each line should be: number, period, space, then ONLY the response label (e.g., "1. Response A")
      - Do not add any other text or explanations in the ranking section

      Return ONLY JSON: {"model":"...","ranking":"..."}.
      If the LLM call fails, return {"model":"...","error":"..."}.
    functions:
      - "ai:call_llm"

  # ------------------------------------------------------------
  # Stage 3: chairman synthesis
  # ------------------------------------------------------------
  - name: "chairman"
    display: "Chairman"
    description: "Synthesize final answer from stage1+stage2."
    model: "default/any"
    parameters:
      type: "object"
      properties:
        model:
          type: "string"
          description: "Chairman model alias/ID."
        query:
          type: "string"
          description: "Original user question."
        stage1_text:
          type: "string"
          description: "Stage 1 responses with model names (rendered text)."
        stage2_text:
          type: "string"
          description: "Stage 2 rankings with model names (rendered text)."
      required:
        - model
        - query
        - stage1_text
        - stage2_text
    instruction: |
      #! mime-type=text/x-go-template
      You are the Chairman of an LLM Council.

      You MUST call ai:call_llm exactly once with:
      - model: {{ .model }}
      - query: a chairman prompt containing:
        Original Question: {{ .query }}
        STAGE 1 - Individual Responses: {{ .stage1_text }}
        STAGE 2 - Peer Rankings: {{ .stage2_text }}

      Return ONLY JSON: {"model":"...","response":"..."}.
      If the LLM call fails, return {"model":"...","error":"..."}.
    functions:
      - "ai:call_llm"

  # ------------------------------------------------------------
  # Title generation (best effort)
  # ------------------------------------------------------------
  - name: "title_generator"
    display: "Title Generator"
    description: "Generate a short conversation title (3‚Äì5 words)."
    model: "default/any"
    parameters:
      type: "object"
      properties:
        model:
          type: "string"
          description: "Title model alias/ID."
        query:
          type: "string"
          description: "Original user question."
      required:
        - model
        - query
    instruction: |
      #! mime-type=text/x-go-template
      Generate a very short title (3-5 words maximum) that summarizes the following question.
      The title should be concise and descriptive. Do not use quotes or punctuation in the title.

      Question: {{ .query }}

      You MUST call ai:call_llm exactly once with:
      - model: {{ .model }}
      - query: the instructions above.

      Return ONLY JSON: {"title":"..."}.
      If the LLM call fails, return {"title":"New Conversation"}.
    functions:
      - "ai:call_llm"

  # ------------------------------------------------------------
  # Ranking parser (ported from council.py logic, but deterministic)
  # ------------------------------------------------------------
  - name: "ranking_parser"
    display: "Ranking Parser"
    description: "Parse a ranking text to an ordered list of Response labels (deterministic)."
    model: "default/any"
    parameters:
      type: "object"
      properties:
        ranking_text:
          type: "string"
          description: "Raw ranking text from a model."
      required:
        - ranking_text
    instruction: |
      #! mime-type=text/x-go-template
      Parse the provided ranking text into an ordered list of labels like ["Response A","Response B"].

      Deterministic algorithm (no external calls):
      1) If the text contains the substring "FINAL RANKING:", take the substring after its first occurrence as the ranking section.
      2) In that ranking section, extract all matches of the regex: \d+\.\s*Response [A-Z]
         - From each match, extract just: Response <LETTER>
         - If any were found, that is the parsed ranking.
      3) Otherwise, extract all matches of the regex: Response [A-Z] from the ranking section.
      4) If "FINAL RANKING:" is not present, fall back to extracting Response [A-Z] from the entire text.
      5) Deduplicate while preserving order.

      Input:
      - ranking_text: {{ .ranking_text }}

      Output: ONLY JSON {"parsed_ranking":[...]}.

      You MUST NOT call any tools.
    functions: []

  - name: "aggregate_ranker"
    display: "Aggregate Ranker"
    description: "Compute aggregate rankings from parsed rankings and label_to_model mapping."
    model: "default/any"
    parameters:
      type: "object"
      properties:
        stage2:
          type: "string"
          description: "JSON array of objects {model, parsed_ranking}."
        label_to_model:
          type: "string"
          description: "JSON object mapping response label to original model."
      required:
        - stage2
        - label_to_model
    instruction: |
      #! mime-type=text/x-go-template
      Compute aggregate rankings.

      Inputs:
      - stage2: {{ .stage2 }}
      - label_to_model: {{ .label_to_model }}

      Method:
      - For each stage2 item, for each label at position i (1-based), map label->model via label_to_model and record the position.
      - For each original model, compute average position across all recorded positions.
      - Round to 2 decimals.
      - Produce array sorted ascending by average_rank:
        [{"model":"...","average_rank":1.75,"rankings_count":4}, ...]

      Return ONLY JSON: {"aggregate_rankings":[...]}.

      You MUST NOT call any tools.
    functions: []
