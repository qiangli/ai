#!/usr/bin/env ai /agent:skills/skills --script

# https://agentskills.io/home
# skills/skills
#
# Implements an AgentSkills-style dispatcher:
# - Find a skill pack folder by agent name under search roots listed in <workspace>/skills/config.md
# - Load <root>/<agent>/skills.md as the prompt
# - Optionally gather allowed tools and pass them to ai:call_llm
# - Append source/reference/scripts paths to the prompt

pack: "skills"
agents:
  - name: "skills"
    display: "Skills Runner"
    description: "Loads a skill pack's skills.md and runs it as an LLM prompt (AgentSkills spec-inspired)."
    model: "default/any"
    embed:
      - "agent:context/lastn"
      - "agent:memory"
    parameters:
      type: "object"
      properties:
        agent:
          type: "string"
          description: "Skill/agent name; will search for <root>/<agent>/skills.md under roots in <workspace>/skills/config.md"
        model:
          type: "string"
          description: "Model alias set/level to use for the final ai:call_llm"
          default: "default/any"
        query:
          type: "string"
          description: "User query to run against the loaded skill prompt"
      required: ["agent", "query"]
    instruction: |
      #! mime-type=text/x-go-template
      You are the Skills agent.

      Goal: given a skills name (parameter `.agent`), locate and run its AgentSkills skill prompt.

      Steps you MUST follow:
      1) Determine workspace path using `sh:workspace`.
      2) Read `<workspace>/skills/config.md`.
         - This file lists top-level folders (absolute paths), one per line (optionally with leading '-', comments starting with '#').
      3) For each folder in config, check whether `<folder>/{{ .agent }}/skills.md` exists.
         - The FIRST match wins.
         - If none found, fail with a clear error listing all checked paths.
      4) Load the matched `skills.md` content.
      5) Parse `skills.md` to find an `allowed-tools` section.
         - If present, collect tool names.
         - Then call `ai:list_tools` and `ai:list_agents` to validate available tools.
         - Pass the intersection of requested allowed-tools with available tools/agents as the `tools` list in `ai:call_llm`.
         - Tool format: tools from ai:list_tools are `kit:name`; agent tools are `agent:pack/name`.
         - If allowed-tools is absent, do NOT pass `tools` (let default tool availability apply).
      6) Build the final `prompt` for `ai:call_llm` as:
         - the loaded skills.md content
         - plus an appended footer with absolute paths:

         Skills Source:
         <absolute path to the matched skills.md>

         If `<root>/{{ .agent }}/references` exists, append:
         Reference:
         <absolute path>

         If `<root>/{{ .agent }}/scripts` exists, append:
         Scripts:
         <absolute path>

      7) Call `ai:call_llm` with:
         - `prompt`: the constructed prompt above
         - `query`: parameter `.query`
         - `models`: parameter `.model` if provided, else use this agent's default model

      Output ONLY the LLM response.

      Notes:
      - You are allowed to use filesystem tools for reading and existence checks.
      - Prefer being strict and explicit when errors occur.
    functions:
      - "sh:*"
      - "fs:*"
      - "ai:*"
